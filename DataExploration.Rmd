---
title: "DataExploration"
author: "Vix Talbot and Haziel Garcia Sanchez"
date: "2024-02-23"
output: html_document
---
Data Description:

The College data set contains a number of variables for 777 different universities and colleges in the US. 
The variables are:

• Private : Public/private indicator
• Apps : Number of applications received
• Accept : Number of applicants accepted
• Enroll : Number of new students enrolled
• Top10perc : New students from top 10 % of high school class 
• Top25perc : New students from top 25 % of high school class 
• F.Undergrad : Number of full-time undergraduates
• P.Undergrad : Number of part-time undergraduates
• Outstate : Out-of-state tuition
• Room.Board : Room and board costs
• Books : Estimated book costs
• Personal : Estimated personal spending
• PhD : Percent of faculty with Ph.D.’s
• Terminal : Percent of faculty with terminal degree 
• S.F.Ratio : Student/faculty ratio
• perc.alumni : Percent of alumni who donate
• Expend : Instructional expenditure per student
• Grad.Rate : Graduation rate

We would like to predict the number of applications received using the other variables.

```{r setup, include=FALSE}
# load and examine the data set
library(ISLR)
library(ISLR2)
library(skimr)
library(ggplot2)

data(College)
head(College)
skim(College)
# double check that our data seems to be clean
missing_values <- is.na(College)
missing_counts <- colSums(missing_values)
print(missing_counts)
# View(College)

```

```{r}

set.seed(1234)
train_indices <- sample(1:nrow(College), nrow(College) / 2)
train <- College[train_indices, ]
test <- College[-train_indices, ]

```



```{r}
# fit a tree to the data and summarize the results.
# this residual mean deviance seems really high
library(tree)

college_tree <- tree(Apps ~ ., data = train)
summary(college_tree)

```


```{r}
# display the tree graphically
# I want to work on making this prettier for the presentation
plot(college_tree)
text(college_tree)

# compare the pruned and un-pruned trees.
unpruned_yhat <- predict(college_tree, newdata= test)
unpruned_data <- data.frame(unpruned_yhat, test$Apps)
ggplot(unpruned_data, aes(x = unpruned_yhat, y = test.Apps)) +
  geom_point(color = "blue") +
  geom_smooth(method = "lm", se = FALSE, color = "salmon") +
  labs(x = "Y-hat value for unpruned tree", y = "Cross-Validation Errors") +
  theme_minimal()
# MSE for unpruned tree
unpruned_MSE <- mean((unpruned_yhat - test$Apps)^2)
unpruned_MSE

```

```{r}
# use LOOCV to determine whether pruning is helpful and determine the optimal size for the pruned tree.
# I'm pretty sure that cv.tree funtion is using LOOCV but I can't find information to support that assumption
tree_cv <- cv.tree(college_tree)
names(tree_cv)
tree_cv

tree_data <- data.frame(Tree_Size = tree_cv$size, Cross_Validation_Errors = tree_cv$dev)

# pretty graphs for presentation
ggplot(tree_data, aes(x = Tree_Size, y = Cross_Validation_Errors)) +
  geom_point(color = "springgreen4", size = 3) +  # Customize points
  geom_line(color = "orange") +  # Add a line connecting points
  labs(x = "Tree Size", y = "Cross-Validation Errors") +  # Customize axis labels
  theme_minimal()  # Apply a minimal theme for a clean appearance
 
```

```{r}
# compare the pruned and un-pruned trees. Report MSE for the pruned tree. Which predictors seem to be the most important?
pruned_college <- prune.tree(college_tree, best = 9)
plot(pruned_college)
text(pruned_college, pretty = 0)

summary(pruned_college)

```

```{r}
# compare the pruned and un-pruned trees. Report MSE for the pruned tree. Which predictors seem to be the most important?
pruned_yhat <- predict(pruned_college, newdata= test)

# putting some ggplot2 graphs in to start using for our presentation
pruned_data <- data.frame(pruned_yhat, test$Apps)
ggplot(pruned_data, aes(x = pruned_yhat, y = test.Apps)) +
  geom_point(color = "purple") +
  geom_smooth(method = "lm", se = FALSE, color = "cyan") +
  labs(x = "Y-hat value for pruned tree", y = "Cross-Validation Errors") +
  theme_minimal()
# MSE for pruned tree
pruned_MSE <- mean((pruned_yhat - test$Apps)^2)
pruned_MSE
 
```
> So far the MSE is identical for the pruned and unpruned trees because we weren't able to get a better fit through the pruning process. The predictors that appear to be important are Accept and Top10Percent.

```{r}
# use a bagging approach to analyze the data with B = 500 Compute the MSE. Which predictors seem to be the most important?

# bagging is just a randomforest where m = p, mtry = 18 so we use all 17 predictors (17 because we have 18 columns but Apps is our response variable)
library(randomForest)

set.seed(5678)
bag500_college <- randomForest(Apps ~ ., data = train, mtry = 17, ntree = 500)

summary(bag500_college)

bag500_yhat <- predict(bag500_college, newdata=test)

# putting some ggplot2 graphs in to start using for our presentation
bagged500_data <- data.frame(bag500_yhat, test$Apps)
ggplot(bagged500_data, aes(x = bag500_yhat, y = test.Apps)) +
  geom_point(color = "magenta") +
  geom_smooth(method = "lm", se = FALSE, color = "royalblue") +
  labs(x = "Y-hat for B = 500", y = "Cross-Validation Errors") +
  theme_minimal()
# MSE for B = 500 bagged tree
bagged500_MSE <- mean((bag500_yhat - test$Apps)^2)
bagged500_MSE

```

```{r}
# use a bagging approach to analyze the data with B = 1000
set.seed(2468)
bag1000_college <- randomForest(Apps ~ ., data = train, mtry = 17, ntree = 1000)

summary(bag1000_college)

bag1000_yhat <- predict(bag1000_college, newdata=test)

# putting some ggplot2 graphs in to start using for our presentation
bagged1000_data <- data.frame(bag1000_yhat, test$Apps)
ggplot(bagged1000_data, aes(x = bag1000_yhat, y = test.Apps)) +
  geom_point(color = "magenta") +
  geom_smooth(method = "lm", se = FALSE, color = "royalblue") +
  labs(x = "Y-hat for B = 1000", y = "Cross-Validation Errors") +
  theme_minimal()
# MSE for B = 1000 bagged
bagged1000_MSE <- mean((bag1000_yhat - test$Apps)^2)
bagged1000_MSE

```

```{r}
# use a random forest approach to analyze the data with B = 500
set.seed(1357)
rf500_college <- randomForest(Apps ~ ., data = train, mtry = 3, ntree = 500)

summary(rf500_college)

rf500_yhat <- predict(rf500_college, newdata=test)

# putting some ggplot2 graphs in to start using for our presentation
rf500_data <- data.frame(rf500_yhat, test$Apps)
ggplot(rf500_data, aes(x = rf500_yhat, y = test.Apps)) +
  geom_point(color = "magenta") +
  geom_smooth(method = "lm", se = FALSE, color = "royalblue") +
  labs(x = "Y-hat for Random Forest B = 500", y = "Cross-Validation Errors") +
  theme_minimal()
# MSE for Random Forest B = 500
rf500_MSE <- mean((rf500_yhat - test$Apps)^2)
rf500_MSE

```
```{r}
# use a random forest approach to analyze the data with B = 1000
set.seed(1278)
rf1000_college <- randomForest(Apps ~ ., data = train, mtry = 3, ntree = 1000)

summary(rf1000_college)

rf1000_yhat <- predict(rf1000_college, newdata=test)

# putting some ggplot2 graphs in to start using for our presentation
rf1000_data <- data.frame(rf1000_yhat, test$Apps)
ggplot(rf1000_data, aes(x = rf1000_yhat, y = test.Apps)) +
  geom_point(color = "magenta") +
  geom_smooth(method = "lm", se = FALSE, color = "royalblue") +
  labs(x = "Y-hat for Random Forest B = 1000", y = "Cross-Validation Errors") +
  theme_minimal()
# MSE for Random Forest B = 1000
rf1000_MSE <- mean((rf1000_yhat - test$Apps)^2)
rf1000_MSE

```

```{r}

# boosting here
library(gbm)
set.seed(1)
boost_college <- gbm(Apps ~ ., data = train,
distribution = "gaussian", n.trees = 50, interaction.depth = 4)

summary(boost_college)

```
```{r}

boost_yhat <- predict(boost_college, newdata=test)

# putting some ggplot2 graphs in to start using for our presentation
boost_data <- data.frame(boost_yhat, test$Apps)
ggplot(boost_data, aes(x = boost_yhat, y = test.Apps)) +
  geom_point(color = "magenta") +
  geom_smooth(method = "lm", se = FALSE, color = "royalblue") +
  labs(x = "Y-hat for Boosting # Trees = 50", y = "Cross-Validation Errors") +
  theme_minimal()
# MSE for Boosting with 50 trees
boost_MSE <- mean((boost_yhat - test$Apps)^2)
boost_MSE

```

```{r}
# compare the results from the various methods. Which method would you recommend?
MSE_vector <- c(unpruned_MSE, pruned_MSE, bagged500_MSE, bagged1000_MSE, rf500_MSE, rf1000_MSE, boost_MSE)
y_values <- seq(0, 20000, length.out = length(MSE_vector))
df <- data.frame(Method = c("unpruned", "pruned", "bagged500", "bagged1000", "rf500", "rf1000", "boost"),
                 MSE = MSE_vector)

# comparison of MSE value for various methods
ggplot(df, aes(x = Method, y = MSE, label = Method)) +
  geom_point(color = "blueviolet", size = 3) +
  geom_text(vjust = -0.5, size = 3) +  
  labs(x = "Methods", y = "MSE", title = "MSE Comparison") +
  theme_minimal()

```
> It appears that the Bagged model with B = 500 yields the lowest MSE for our data.
